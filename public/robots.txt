# robots.txt for btsowa.dev
# SEO & AI Search Optimization (AEO)

# Allow all traditional search engines
User-agent: *
Allow: /

# ============================================
# AI SEARCH/RETRIEVAL CRAWLERS (Allowed)
# These crawlers are used for AI-powered search
# and answer engines, not for training
# ============================================

User-agent: ChatGPT-User
Allow: /

User-agent: OAI-SearchBot
Allow: /

User-agent: Claude-User
Allow: /

User-agent: Claude-SearchBot
Allow: /

User-agent: Google-CloudVertexBot
Allow: /

User-agent: Gemini-Deep-Research
Allow: /

User-agent: PerplexityBot
Allow: /

User-agent: Perplexity-User
Allow: /

User-agent: Meta-WebIndexer
Allow: /

User-agent: DuckAssistBot
Allow: /

User-agent: MistralAI-User
Allow: /

# ============================================
# AI TRAINING CRAWLERS (Blocked)
# These crawlers collect data for AI model
# training - block to protect content
# ============================================

User-agent: GPTBot
Disallow: /

User-agent: ClaudeBot
Disallow: /

User-agent: Google-Extended
Disallow: /

User-agent: Meta-ExternalAgent
Disallow: /

User-agent: Bytespider
Disallow: /

User-agent: Amazonbot
Disallow: /

User-agent: CCBot
Disallow: /

User-agent: Diffbot
Disallow: /

User-agent: ICC-Crawler
Disallow: /

User-agent: Webz.io
Disallow: /

User-agent: Cohere-AI
Disallow: /

User-agent: anthropic-ai
Disallow: /

User-agent: Omgilibot
Disallow: /

User-agent: FacebookBot
Disallow: /

# ============================================
# GENERAL SETTINGS
# ============================================

# Sitemap location
Sitemap: https://btsowa.dev/sitemap.xml

# Crawl delay (be considerate to the server)
Crawl-delay: 1

# Disallow admin/private paths
Disallow: /api/
Disallow: /_*
